{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import pickle\n",
    "import scienceplots\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.style.use(['science','grid','notebook'])\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "\n",
    "info_lutador = pd.read_csv('fighter_details.csv')\n",
    "ufc = pd.read_csv('total_fight_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['R_SIG_STR.', 'B_SIG_STR.', 'R_TOTAL_STR.', 'B_TOTAL_STR.',\n",
    "       'R_TD', 'B_TD', 'R_HEAD', 'B_HEAD', 'R_BODY','B_BODY', 'R_LEG', 'B_LEG', \n",
    "        'R_DISTANCE', 'B_DISTANCE', 'R_CLINCH','B_CLINCH', 'R_GROUND', 'B_GROUND']\n",
    "\n",
    "attemp = '_att'\n",
    "landed = '_landed'\n",
    "\n",
    "for column in columns:\n",
    "    ufc[column+attemp] = ufc[column].apply(lambda X:int(X.split('of')[1]))\n",
    "    ufc[column+landed] = ufc[column].apply(lambda X:int(X.split('of')[0]))\n",
    "\n",
    "ufc.drop(columns, axis=1, inplace=True)\n",
    "ufc['Winner'].fillna('Draw', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconder(x):\n",
    "    mins, secs = map(float, x.split(':'))\n",
    "    td = timedelta(minutes=mins, seconds=secs)\n",
    "    return td.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_columns = ['R_SIG_STR_pct','B_SIG_STR_pct', 'R_TD_pct', 'B_TD_pct']\n",
    "\n",
    "for column in pct_columns:\n",
    "    ufc[column].replace('---','0.0%', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_columns = ['R_REV', 'B_REV']\n",
    "\n",
    "for column in rev_columns:\n",
    "    ufc[column].replace('--','0:0', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc['R_REV'] = ufc['R_REV'].apply(seconder)\n",
    "ufc['B_REV'] = ufc['B_REV'].apply(seconder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in pct_columns:\n",
    "    ufc[column] = ufc[column].apply(lambda X:float(X.replace('%', ''))/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Division(X):\n",
    "    for division in weight_classes:\n",
    "        if division in X:\n",
    "            return division\n",
    "    if X == 'Catch Weight Bout' or 'Catchweight Bout':\n",
    "        return 'Catch Weight'\n",
    "    else:\n",
    "        return 'Open Weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_classes = ['Women\\'s Strawweight', 'Women\\'s Bantamweight', \n",
    "                  'Women\\'s Featherweight', 'Women\\'s Flyweight', 'Lightweight', \n",
    "                  'Welterweight', 'Middleweight','Light Heavyweight', \n",
    "                  'Heavyweight', 'Featherweight','Bantamweight', 'Flyweight', 'Open Weight']\n",
    "\n",
    "ufc['Weight_class'] = ufc['Fight_type'].apply(Division)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc['Winner'].fillna('Draw', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_renamed_winner(row):\n",
    "    if row['R_fighter'] == row['Winner']:\n",
    "        return 'Red'\n",
    "    if row['B_fighter'] == row['Winner']:\n",
    "        return 'Blue'\n",
    "    elif row['Winner'] == 'Draw':\n",
    "        return 'Draw'\n",
    "    \n",
    "ufc['Winner'] = ufc[['R_fighter', 'B_fighter', 'Winner']].apply(get_renamed_winner, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inch_to_cm(X):\n",
    "    if X is np.NaN:\n",
    "        return X\n",
    "    elif len(X.split(\"'\")) == 2:\n",
    "        feet = float(X.split(\"'\")[0])\n",
    "        inches = int(X.split(\"'\")[1].replace(' ','').replace('\"', ''))\n",
    "        return (feet*30.48) + (inches * 2.54)\n",
    "    else:\n",
    "        return float(X.replace('\"',''))*2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_lutador['Height'] = info_lutador['Height'].apply(inch_to_cm)\n",
    "info_lutador['Reach'] = info_lutador['Reach'].apply(inch_to_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_lutador['Weight'] = info_lutador['Weight'].apply(lambda X: float(X.replace(' lbs', '')) if X is not np.NaN else X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final = ufc.merge(info_lutador, left_on='B_fighter', right_on='fighter_name', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighters = []\n",
    "for j in ufc_final['R_fighter']:\n",
    "    if j not in fighters:\n",
    "        fighters.append(j)\n",
    "for i in ufc_final['B_fighter']:\n",
    "    if i not in fighters:\n",
    "        fighters.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2416"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fighters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final = ufc_final.drop('fighter_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final.rename(columns={'Height':'R_Height',\n",
    "                          'Weight':'R_Weight',\n",
    "                          'Reach':'R_Reach',\n",
    "                          'Stance':'R_Stance',\n",
    "                          'DOB':'R_DOB'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final = ufc_final.merge(info_lutador, left_on='B_fighter', right_on='fighter_name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final = ufc_final.drop('fighter_name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final.rename(columns={'Height':'B_Height',\n",
    "                          'Weight':'B_Weight',\n",
    "                          'Reach':'B_Reach',\n",
    "                          'Stance':'B_Stance',\n",
    "                          'DOB':'B_DOB'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final['R_DOB'] = pd.to_datetime(ufc_final['R_DOB'])\n",
    "ufc_final['B_DOB'] = pd.to_datetime(ufc_final['B_DOB'])\n",
    "ufc_final['date'] = pd.to_datetime(ufc_final['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final['R_year'] = ufc_final['R_DOB'].apply(lambda X: X.year)\n",
    "ufc_final['B_year'] = ufc_final['B_DOB']. apply(lambda X: X.year)\n",
    "ufc_final['date_year'] = ufc_final['date'].apply(lambda X: X.year)\n",
    "\n",
    "\n",
    "def get_age(row):\n",
    "    B_age = (row['date_year'] - row['B_year'])\n",
    "    R_age = (row['date_year'] - row['R_year'])\n",
    "    if np.isnan(B_age) != True:\n",
    "        B_age = B_age\n",
    "    if np.isnan(R_age) != True:\n",
    "        R_age = R_age\n",
    "    return pd.Series([B_age, R_age], index = ['B_age', 'R_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final[['B_age', 'R_age']] = ufc_final[['date_year', 'R_year', 'B_year']].apply(get_age, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final.drop(['R_DOB', 'B_DOB', 'B_year', 'R_year'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final['R_age'] = ufc_final['R_age'].fillna(ufc_final['R_age'].median())\n",
    "ufc_final['B_age'] = ufc_final['B_age'].fillna(ufc_final['B_age'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final['R_Height'] = ufc_final['R_Height'].fillna(ufc_final['R_Height'].mean())\n",
    "ufc_final['B_Height'] = ufc_final['B_Height'].fillna(ufc_final['B_Height'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "ufc_final['B_Stance'] = ufc_final['B_Stance'].fillna(ufc_final['B_Stance'].mode()[0])\n",
    "ufc_final['R_Stance'] = ufc_final['R_Stance'].fillna(ufc_final['R_Stance'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_enc1 = ufc_final['Weight_class']\n",
    "data_enc1 = enc.fit_transform(data_enc1)\n",
    "\n",
    "data_enc2 = ufc_final['R_Stance']\n",
    "data_enc2 = enc.fit_transform(data_enc2)\n",
    "\n",
    "data_enc3 = ufc_final['B_Stance']\n",
    "data_enc3 = enc.fit_transform(data_enc3)\n",
    "\n",
    "data_enc2 = pd.DataFrame(data_enc2, columns=['R_Stance'])\n",
    "data_enc3 = pd.DataFrame(data_enc3, columns=['B_Stance'])\n",
    "\n",
    "ufc_final[['R_Stance']] = data_enc2[['R_Stance']]\n",
    "ufc_final[['B_Stance']] = data_enc3[['B_Stance']]\n",
    "\n",
    "R_S = pd.get_dummies(ufc_final['R_Stance'])\n",
    "B_S = pd.get_dummies(ufc_final['B_Stance'])\n",
    "\n",
    "ufc_final = pd.concat([ufc_final,pd.get_dummies(ufc_final['win_by'], prefix='win_by')], axis=1)\n",
    "ufc_final.drop(['win_by'], axis=1, inplace=True)\n",
    "\n",
    "ufc_final['Winner_num'] = ufc_final.Winner.map({'Red':0, 'Blue':1, 'Draw':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_S.drop([0,2], axis=1, inplace=True)\n",
    "R_S.drop([0,2], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_S.columns = ['B_Southpaw','B_Orthodox','B_Switch']\n",
    "R_S.columns = ['R_Southpaw','R_Orthodox','R_Switch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final['B_Southpaw'] = B_S['B_Southpaw']\n",
    "ufc_final['B_Orthodox']= B_S['B_Orthodox']\n",
    "ufc_final['B_Switch'] = B_S['B_Switch']\n",
    "ufc_final['R_Southpaw'] = R_S['R_Southpaw']\n",
    "ufc_final['R_Orthodox']= R_S['R_Orthodox']\n",
    "ufc_final['R_Switch'] = R_S['R_Switch']\n",
    "\n",
    "ufc_final.drop(['R_Stance','B_Stance'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final = ufc_final[ufc_final['Winner_num']!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final.drop(['date', 'location', 'Referee', 'last_round', 'last_round_time', 'Format', 'Winner','date_year','Fight_type','Weight_class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ufc_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['R_SUB._ATT'] = df['R_SUB_ATT']\n",
    "df['R_SIG_STR._pct'] = df['R_SIG_STR_pct']\n",
    "df['B_SUB._ATT'] = df['B_SUB_ATT']\n",
    "df['B_SIG_STR._pct'] = df['B_SIG_STR_pct']\n",
    "df.drop(['B_SUB_ATT','B_SIG_STR_pct', 'R_SUB_ATT', 'R_SIG_STR_pct'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final.drop(['R_SIG_STR._att',\n",
    "                'B_SIG_STR._att',\n",
    "                'R_SIG_STR._landed',\n",
    "                'B_SIG_STR._landed',\n",
    "                'win_by_Could Not Continue',\n",
    "                'win_by_DQ',\n",
    "                'win_by_Decision - Majority',\n",
    "                'win_by_Decision - Split',\n",
    "                'win_by_Decision - Unanimous',\n",
    "                'win_by_KO/TKO',\n",
    "                'win_by_Other',\n",
    "                'win_by_Overturned',\n",
    "                'win_by_Submission',\n",
    "                \"win_by_TKO - Doctor's Stoppage\"\n",
    "               ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final['R_TOTAL_STR._pct'] = ufc_final['R_TOTAL_STR._landed']/ufc_final['R_TOTAL_STR._att']\n",
    "ufc_final['R_BODY_pct'] = ufc_final['R_BODY_landed']/ufc_final['R_BODY_att']\n",
    "ufc_final['R_CLINCH_pct'] = ufc_final['R_CLINCH_landed']/ufc_final['R_CLINCH_att']\n",
    "ufc_final['R_DISTANCE_pct'] = ufc_final['R_DISTANCE_landed']/ufc_final['R_DISTANCE_att']\n",
    "ufc_final['R_GROUND_pct'] = ufc_final['R_GROUND_landed']/ufc_final['R_GROUND_att']\n",
    "ufc_final['R_HEAD_pct'] = ufc_final['R_HEAD_landed']/ufc_final['R_HEAD_att']\n",
    "ufc_final['R_LEG_pct'] = ufc_final['R_LEG_landed']/ufc_final['R_LEG_att']\n",
    "ufc_final['R_TD_pct'] = ufc_final['R_TD_landed']/ufc_final['R_TD_att']\n",
    "ufc_final['R_SUB._pct'] = ufc_final['R_SUB_ATT']\n",
    "ufc_final['R_SIG_STR._pct'] = ufc_final['R_SIG_STR_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final['B_TOTAL_STR._pct'] = ufc_final['B_TOTAL_STR._landed']/ufc_final['B_TOTAL_STR._att']\n",
    "ufc_final['B_BODY_pct'] = ufc_final['B_BODY_landed']/ufc_final['B_BODY_att']\n",
    "ufc_final['B_CLINCH_pct'] = ufc_final['B_CLINCH_landed']/ufc_final['B_CLINCH_att']\n",
    "ufc_final['B_DISTANCE_pct'] = ufc_final['B_DISTANCE_landed']/ufc_final['B_DISTANCE_att']\n",
    "ufc_final['B_GROUND_pct'] = ufc_final['B_GROUND_landed']/ufc_final['B_GROUND_att']\n",
    "ufc_final['B_HEAD_pct'] = ufc_final['B_HEAD_landed']/ufc_final['B_HEAD_att']\n",
    "ufc_final['B_LEG_pct'] = ufc_final['B_LEG_landed']/ufc_final['B_LEG_att']\n",
    "ufc_final['B_TD_pct'] = ufc_final['B_TD_landed']/ufc_final['B_TD_att']\n",
    "ufc_final['B_SUB._pct'] = ufc_final['B_SUB_ATT']\n",
    "ufc_final['B_SIG_STR._pct'] = ufc_final['B_SIG_STR_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final.drop(['R_TOTAL_STR._landed',\n",
    "                'R_TOTAL_STR._att',\n",
    "                'B_TOTAL_STR._landed',\n",
    "                'B_TOTAL_STR._att',\n",
    "                'R_BODY_att',\n",
    "                'R_BODY_landed',\n",
    "                'R_CLINCH_att',\n",
    "                'R_CLINCH_landed',\n",
    "                'R_DISTANCE_att',\n",
    "                'R_DISTANCE_landed',\n",
    "                'R_GROUND_att',\n",
    "                'R_GROUND_landed',\n",
    "                'R_HEAD_att',\n",
    "                'R_HEAD_landed',\n",
    "                'R_LEG_att',\n",
    "                'R_LEG_landed',\n",
    "                'R_BODY_att',\n",
    "                'R_BODY_landed',\n",
    "                'R_TD_att',\n",
    "                'R_TD_landed',\n",
    "                'B_BODY_att',\n",
    "                'B_BODY_landed',\n",
    "                'B_CLINCH_att',\n",
    "                'B_CLINCH_landed',\n",
    "                'B_DISTANCE_att',\n",
    "                'B_DISTANCE_landed',\n",
    "                'B_GROUND_att',\n",
    "                'B_GROUND_landed',\n",
    "                'B_HEAD_att',\n",
    "                'B_HEAD_landed',\n",
    "                'B_LEG_att',\n",
    "                'B_LEG_landed',\n",
    "                'B_BODY_att',\n",
    "                'B_BODY_landed',\n",
    "                'B_TD_att',\n",
    "                'B_TD_landed',\n",
    "                'B_SUB_ATT',\n",
    "                'R_SUB_ATT',\n",
    "                'R_SIG_STR_pct',\n",
    "                'B_SIG_STR_pct'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pct(att, landed):\n",
    "    pct = (landed / att) * 100\n",
    "    return pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_pct(r_pct, b_pct):\n",
    "    average_pct = (r_pct.median() + b_pct.median())/2\n",
    "    return average_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aumentar quantidade de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_enhancement(df):\n",
    "    \n",
    "#     columns = df.columns\n",
    "#     df.columns = df.columns.str.replace('R_','B_')\n",
    "#     df['Winner_num'] = df['Winner_num'].replace(1,'blue')\n",
    "#     df['Winner_num'] = df['Winner_num'].replace(0,'red')\n",
    "#     df['Winner_num'] = df['Winner_num'].replace('red',0)\n",
    "#     df['Winner_num'] = df['Winner_num'].replace('blue',1)\n",
    "#     df.columns = columns\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# ufc_final2 = data_enhancement(ufc_final)\n",
    "# ufc_final = pd.concat([ufc_final, ufc_final2],ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns  = ['KD', 'TD_pct', 'PASS', 'REV', 'Height', 'Weight',\n",
    "            'Reach', 'age', 'Southpaw', 'Orthodox', 'Switch',\n",
    "            'TOTAL_STR._pct', 'BODY_pct', 'CLINCH_pct', 'DISTANCE_pct',\n",
    "            'GROUND_pct', 'HEAD_pct', 'LEG_pct', 'SUB._pct',\n",
    "            'SIG_STR._pct', 'Wins']\n",
    "R_columns = ufc_final.filter(regex=('R_')).columns[1:]\n",
    "B_columns = ufc_final.filter(regex=('B_')).columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções para pegar dados dos lutadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fighter_df(fighter_R, fighter_B):\n",
    "    \n",
    "    f_r = df_fighters.loc[fighter_R]\n",
    "    f_b = df_fighters.loc[fighter_B]\n",
    "\n",
    "    R_columns = ufc_final.filter(regex=('R_')).columns[1:]\n",
    "    B_columns = ufc_final.filter(regex=('B_')).columns[1:]\n",
    "    \n",
    "    f_r.index = R_columns\n",
    "    f_b.index = B_columns\n",
    "    \n",
    "    fighter_r = f_r.to_dict()\n",
    "    fighter_b = f_b.to_dict()\n",
    "\n",
    "    fighter_r.update(fighter_b)\n",
    "    \n",
    "    fighter_test = pd.DataFrame(fighter_r, columns=fighter_r.keys() , index=[0])\n",
    "    \n",
    "    \n",
    "    return fighter_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fighter_hist(name):\n",
    "    \n",
    "    r_f = ufc_final[ufc_final['R_fighter']==name][R_columns]\n",
    "    b_f = ufc_final[ufc_final['B_fighter']==name][B_columns]\n",
    "\n",
    "    \n",
    "    r_f = r_f.rename(columns={'R_fighter':'Fighter'})\n",
    "    b_f = b_f.rename(columns={'B_fighter':'Fighter'})\n",
    "    \n",
    "    r_f.columns = r_f.columns.str.replace(\"R_\",'')\n",
    "    b_f.columns = b_f.columns.str.replace(\"B_\",'')\n",
    "    \n",
    "    fighter_history = pd.concat([r_f, b_f],axis=0)    \n",
    "\n",
    "    return fighter_history.sort_values('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for fighter in fighters:\n",
    "    d[\"{0}\".format(fighter)] = get_fighter_hist(fighter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fighter in fighters:\n",
    "    d[fighter].mean()\n",
    "    d[fighter] = d[fighter].apply(lambda x: x.fillna(x.mean(), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fighter_info(name):\n",
    "    a = d[name].mean(axis=0)\n",
    "    b = d[name].mean(axis=0)\n",
    "    c = (a.values + b.values)/2\n",
    "    k = {key: value for key, value in zip(columns, c.round(2))}\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = []\n",
    "for i in fighters:\n",
    "    lista.append(get_fighter_info(i))\n",
    "\n",
    "\n",
    "df_fighters = pd.DataFrame(data=lista, index=fighters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_fighters = []\n",
    "for fighter in fighters:\n",
    "    if d[fighter].empty:\n",
    "        empty_fighters.append(fighter)\n",
    "\n",
    "df_fighters.dropna(axis=0, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fighters.to_excel('fighter_info.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mudar ufc_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['R_KD', 'R_TD_pct', 'R_PASS', 'R_REV', 'R_Height', 'R_Weight',\n",
    "       'R_Reach', 'R_age', 'R_Southpaw', 'R_Orthodox', 'R_Switch',\n",
    "       'R_TOTAL_STR._pct', 'R_BODY_pct', 'R_CLINCH_pct', 'R_DISTANCE_pct',\n",
    "       'R_GROUND_pct', 'R_HEAD_pct', 'R_LEG_pct', 'R_SUB._pct',\n",
    "       'R_SIG_STR._pct', 'B_KD', 'B_TD_pct', 'B_PASS', 'B_REV', 'B_Height',\n",
    "       'B_Weight', 'B_Reach', 'B_age', 'B_Southpaw', 'B_Orthodox', 'B_Switch',\n",
    "       'B_TOTAL_STR._pct', 'B_BODY_pct', 'B_CLINCH_pct', 'B_DISTANCE_pct',\n",
    "       'B_GROUND_pct', 'B_HEAD_pct', 'B_LEG_pct', 'B_SUB._pct',\n",
    "       'B_SIG_STR._pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(df, num_samples):\n",
    "    new_rows = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        new_row = {}\n",
    "        for column in df.columns:\n",
    "            new_row[column] = np.random.choice(df[column])\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "    return pd.DataFrame(new_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fights_df(fighter_R, fighter_B):\n",
    "    \n",
    "    f_r = df_fighters.loc[fighter_R]\n",
    "    f_b = df_fighters.loc[fighter_B]\n",
    "\n",
    "    R_columns = ufc_final.filter(regex=('R_')).columns[1:]\n",
    "    B_columns = ufc_final.filter(regex=('B_')).columns[1:]\n",
    "    \n",
    "    f_r.index = R_columns\n",
    "    f_b.index = B_columns\n",
    "    \n",
    "    fighter_r = f_r.to_dict()\n",
    "    fighter_b = f_b.to_dict()\n",
    "\n",
    "    fighter_r.update(fighter_b)\n",
    "        \n",
    "    \n",
    "    return fighter_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "fights = ufc_final[['R_fighter','B_fighter']]\n",
    "fights = list(fights.values)\n",
    "f = [get_fights_df(fight[0],fight[1]) for fight in fights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_means = pd.DataFrame(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_means[['R_fighter','B_fighter']] = ufc_final[['R_fighter','B_fighter']]\n",
    "ufc_means['Winner_num'] = ufc_final['Winner_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_means['R_Reach'].fillna(ufc_means['R_Height'],inplace=True)\n",
    "ufc_means['B_Reach'].fillna(ufc_means['B_Height'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ufc_means.columns\n",
    "# ufc_means[cols].fillna(ufc_means[cols].median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan(df, series):\n",
    "    df[series].fillna(df[series].median(),inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['R_KD', 'R_TD_pct', 'R_PASS', 'R_REV', 'R_Height', 'R_Weight',\n",
    "       'R_Reach', 'R_age', 'R_Southpaw', 'R_Orthodox', 'R_Switch',\n",
    "       'R_TOTAL_STR._pct', 'R_BODY_pct', 'R_CLINCH_pct', 'R_DISTANCE_pct',\n",
    "       'R_GROUND_pct', 'R_HEAD_pct', 'R_LEG_pct', 'R_SUB._pct',\n",
    "       'R_SIG_STR._pct', 'B_KD', 'B_TD_pct', 'B_PASS', 'B_REV', 'B_Height',\n",
    "       'B_Weight', 'B_Reach', 'B_age', 'B_Southpaw', 'B_Orthodox', 'B_Switch',\n",
    "       'B_TOTAL_STR._pct', 'B_BODY_pct', 'B_CLINCH_pct', 'B_DISTANCE_pct',\n",
    "       'B_GROUND_pct', 'B_HEAD_pct', 'B_LEG_pct', 'B_SUB._pct',\n",
    "       'B_SIG_STR._pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    replace_nan(ufc_means, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final['R_Reach'].fillna(ufc_final['R_Height'],inplace=True)\n",
    "ufc_final['B_Reach'].fillna(ufc_final['B_Height'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    replace_nan(ufc_final, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ufc_final = ufc_final.dropna(axis=0)\n",
    "X = ufc_final.drop('Winner_num', axis=1)\n",
    "y = ufc_final['Winner_num']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "X_test, X_mc_test, y_test, y_mc_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "log = linear_model.LogisticRegression()\n",
    "log.fit(X_train.iloc[:,2:],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = log.predict(X_test.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 82.82%, precision= 80.93%, recall= 80.18%, mse=  0.17\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred, average = 'macro')\n",
    "recall = recall_score(y_test, pred, average = 'macro')\n",
    "\n",
    "print('accuracy= %.2f%%, precision= %.2f%%, recall= %.2f%%, mse= ' % (accuracy*100, precision*100, recall*100), mean_squared_error(y_test, pred).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = log.fit(X.iloc[:,2:], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'logistic_raw_model.sav'\n",
    "pickle.dump(logistic_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.metrics import make_scorer\n",
    "\n",
    "#randmodel=XGBClassifier()\n",
    "\n",
    "#randparams={'subsample':[0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "#            'reg_alpha':[10e-5, 10e-3, 0.01, 0.1, 1, 10, 100],\n",
    "#            'min_child_weight':[2,3,4,5,6,7,8,9,10,15,20,30],\n",
    "#            'max_depth':[4,5,6,7,8,9,10,15,20,25,30,35,40,45,50,55,100],\n",
    "#            'gamma':[0.01,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,2],\n",
    "#            'eta':[0.001,0.003,0.005,0.007,0.01,0.03,0.05,0.07,0.1,0.3,0.5,0.7,0.9], \n",
    "#            'colsample_bytree':[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]}\n",
    "\n",
    "#clf_model = RandomizedSearchCV(randmodel, param_distributions=randparams, n_iter=500, cv=7, scoring='roc_auc', n_jobs=5, verbose=3)\n",
    "\n",
    "#search = clf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(search.best_params_, '\\n', '\\n', search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 85.70%, precision= 84.15%, recall= 83.57%, mse=  0.14\n"
     ]
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(objective='binary:logistic',\n",
    "                      subsample='0.9',\n",
    "                      reg_alpha='0.1',\n",
    "                      min_child_weight='2',\n",
    "                      max_depth='25',\n",
    "                      gamma='0.3',\n",
    "                      eta='0.07',\n",
    "                      colsample_bytree='0.6')\n",
    "\n",
    "model_xgb.fit(X_train.iloc[:,2:], y_train)\n",
    "pred = model_xgb.predict(X_test.iloc[:,2:])\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred, average = 'macro')\n",
    "recall = recall_score(y_test, pred, average = 'macro')\n",
    "\n",
    "print('accuracy= %.2f%%, precision= %.2f%%, recall= %.2f%%, mse= ' % (accuracy*100, precision*100, recall*100), mean_squared_error(y_test, pred).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'xgb_raw_model.sav'\n",
    "pickle.dump(model_xgb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_auc_score(y_test, yhat).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive-Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 80.04%, precision= 77.90%, recall= 80.06%, mse=  0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn.naive_bayes\n",
    "\n",
    "model_bayes = sklearn.naive_bayes.GaussianNB()\n",
    "\n",
    "model_bayes.fit(X_train.iloc[:,2:], y_train)\n",
    "pred = model_bayes.predict(X_test.iloc[:,2:])\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred, average = 'macro')\n",
    "recall = recall_score(y_test, pred, average = 'macro')\n",
    "\n",
    "print('accuracy= %.2f%%, precision= %.2f%%, recall= %.2f%%, mse= ' % (accuracy*100, precision*100, recall*100), mean_squared_error(y_test, pred).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'nb_raw_model.sav'\n",
    "pickle.dump(model_bayes, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM-SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 83.10%, precision= 81.07%, recall= 81.07%, mse=  0.17\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC(kernel='linear', gamma='auto', decision_function_shape='ovr', probability=True)\n",
    "\n",
    "svm_model.fit(X_train.iloc[:,2:], y_train)\n",
    "pred = svm_model.predict(X_test.iloc[:,2:])\n",
    "\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "precision = precision_score(y_test, pred, average = 'macro')\n",
    "recall = recall_score(y_test, pred, average = 'macro')\n",
    "\n",
    "print('accuracy= %.2f%%, precision= %.2f%%, recall= %.2f%%, mse= ' % (accuracy*100, precision*100, recall*100), mean_squared_error(y_test, pred).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, pred).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'svc_raw_model.sav'\n",
    "pickle.dump(svm_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "estimators=[\n",
    "('xgb', model_xgb),\n",
    "('svc', svm_model),\n",
    "('nb', model_bayes),   \n",
    "('lr', logistic_model)])\n",
    "voting_clf.voting = \"soft\"\n",
    "voting_clf.fit(X_train.iloc[:,2:], y_train)\n",
    "pred = voting_clf.predict(X_test.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb = 0.8570102135561746\n",
      "svc = 0.8310120705663882\n",
      "nb = 0.8003714020427113\n",
      "lr = 0.8282265552460538\n"
     ]
    }
   ],
   "source": [
    "for name, clf in voting_clf.named_estimators_.items():\n",
    "    print(name, \"=\", clf.score(X_test.iloc[:,2:], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8347260909935005"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_test.iloc[:,2:], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ensemble_model_combined.sav'\n",
    "pickle.dump(voting_clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols = X_train.iloc[:,2:].columns\n",
    "cols_ = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list = [[item1, item2] for item1, item2 in zip(X_mc_test.iloc[:,:2]['R_fighter'],\n",
    "                                                        X_mc_test.iloc[:,:2]['B_fighter'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_log_prediction = []\n",
    "most_common_xgb_prediction = []\n",
    "most_common_nb_prediction = []\n",
    "most_common_svc_prediction = []\n",
    "most_common_voting_clf_pred = []\n",
    "\n",
    "for i in combined_list:\n",
    "    a = generate_samples(get_fighter_hist(i[0]),1000)\n",
    "    R_a = a.add_prefix('R_')\n",
    "    R_a['R_fighter'] = i[0]\n",
    "    b = generate_samples(get_fighter_hist(i[1]),1000)\n",
    "    B_b = b.add_prefix('B_')\n",
    "    B_b['B_fighter'] = i[1]\n",
    "    samples = pd.concat([R_a, B_b], axis=1)\n",
    "    samples = samples[model_cols]\n",
    "    predictions_log = logistic_model.predict(samples)\n",
    "    predictions_xgb = model_xgb.predict(samples)\n",
    "    predictions_nb = model_bayes.predict(samples)\n",
    "    predictions_svm = svm_model.predict(samples)\n",
    "    voting_clf_pred = voting_clf.predict(samples)\n",
    "    most_common_log_prediction.append(stats.mode(predictions_log)[0])\n",
    "    most_common_xgb_prediction.append(stats.mode(predictions_xgb)[0])\n",
    "    most_common_nb_prediction.append(stats.mode(predictions_nb)[0])\n",
    "    most_common_svc_prediction.append(stats.mode(predictions_svm)[0])\n",
    "    most_common_voting_clf_pred.append(stats.mode(voting_clf_pred)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_log = accuracy_score(y_mc_test, most_common_log_prediction)\n",
    "accuracy_xgb = accuracy_score(y_mc_test, most_common_xgb_prediction)\n",
    "accuracy_nb = accuracy_score(y_mc_test, most_common_nb_prediction)\n",
    "accuracy_svc = accuracy_score(y_mc_test, most_common_svc_prediction)\n",
    "accuracy_voting = accuracy_score(y_mc_test, most_common_voting_clf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6898792943361188 0.7084493964716806 0.6768802228412256 0.6945218198700093 0.6926648096564532\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_log, accuracy_xgb, accuracy_nb, accuracy_svc, accuracy_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('future_fights','r')\n",
    "lutas = f.read().replace(\"\\\"\\\"\", \"\").split('\\n')[:-1]\n",
    "f.close()\n",
    "\n",
    "lutas = [x.replace('[','') for x in lutas]\n",
    "lutas = [x.replace(']','') for x in lutas]\n",
    "lutas = [x.replace(\"'\",'') for x in lutas]\n",
    "lutas = [x.split(',') for x in lutas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fighters = []\n",
    "most_common_log_prediction = []\n",
    "most_common_xgb_prediction = []\n",
    "most_common_nb_prediction = []\n",
    "most_common_svc_prediction = []\n",
    "most_common_voting_clf_pred = []\n",
    "\n",
    "for i in lutas:\n",
    "    try:\n",
    "        a = generate_samples(get_fighter_hist(i[0]),500)\n",
    "        R_a = a.add_prefix('R_')\n",
    "        R_a['R_fighter'] = i[0]\n",
    "        b = generate_samples(get_fighter_hist(i[1]),500)\n",
    "        B_b = b.add_prefix('B_')\n",
    "        B_b['B_fighter'] = i[1]\n",
    "        samples = pd.concat([R_a, B_b], axis=1)\n",
    "        samples = samples[model_cols]\n",
    "\n",
    "        fighters.append([i[0],i[1]])\n",
    "\n",
    "        predictions_log = logistic_model.predict(samples)\n",
    "        predictions_xgb = model_xgb.predict(samples)\n",
    "        predictions_nb = model_bayes.predict(samples)\n",
    "        predictions_svm = svm_model.predict(samples)\n",
    "        voting_clf_pred = voting_clf.predict(samples)\n",
    "        most_common_log_prediction.append(stats.mode(predictions_log)[0])\n",
    "        most_common_xgb_prediction.append(stats.mode(predictions_xgb)[0])\n",
    "        most_common_nb_prediction.append(stats.mode(predictions_nb)[0])\n",
    "        most_common_svc_prediction.append(stats.mode(predictions_svm)[0])\n",
    "        most_common_voting_clf_pred.append(stats.mode(voting_clf_pred)[0])\n",
    "    \n",
    "    except:\n",
    "        fighters.append('nan')\n",
    "        most_common_log_prediction.append('nan')\n",
    "        most_common_xgb_prediction.append('nan')\n",
    "        most_common_nb_prediction.append('nan')\n",
    "        most_common_svc_prediction.append('nan')\n",
    "        most_common_voting_clf_pred.append('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beneil Dariush', 'Arman Tsarukyan'] 0.0\n",
      "['Jalin Turner', 'Bobby Green'] 0.0\n",
      "['Rob Font', 'Deiveson Figueiredo'] 1.0\n",
      "['Sean Brady', 'Kelvin Gastelum'] 0.0\n",
      "['Clay Guida', 'Joaquim Silva'] 0.0\n",
      "['Punahele Soriano', 'Dustin Stoltzfus'] 0.0\n",
      "['Miesha Tate', 'Julia Avila'] 1.0\n",
      "nan nan\n",
      "['Drakkar Klose', 'Joe Solecki'] 1.0\n",
      "nan nan\n",
      "['Wellington Turman', 'Jared Gooden'] 0.0\n",
      "['Veronica Hardy', 'Jamey-Lyn Horth'] 0.0\n",
      "['Song Yadong', 'Chris Gutierrez'] 0.0\n",
      "['Anthony Smith', 'Khalil Rountree Jr.'] 1.0\n",
      "['Sumudaerji', 'Allan Nascimento'] 0.0\n",
      "['Nasrat Haqparast', 'Jamie Mullarkey'] 1.0\n",
      "['JunYong Park', 'Andre Muniz'] 0.0\n",
      "['Song Kenan', 'Kevin Jousset'] 0.0\n",
      "['Tatsuro Taira', 'Carlos Hernandez'] 0.0\n",
      "['HyunSung Park', 'Shannon Ross'] 0.0\n",
      "['Luana Santos', 'Stephanie Egger'] 1.0\n",
      "nan nan\n",
      "['Leon Edwards', 'Colby Covington'] 1.0\n",
      "['Alexandre Pantoja', 'Brandon Royval'] 0.0\n",
      "['Shavkat Rakhmonov', 'Stephen Thompson'] 0.0\n",
      "['Tony Ferguson', 'Paddy Pimblett'] 1.0\n",
      "['Vicente Luque', 'Ian Garry'] 1.0\n",
      "['Josh Emmett', 'Giga Chikadze'] 1.0\n",
      "['Irene Aldana', 'Karol Rosa'] 1.0\n",
      "['Cody Garbrandt', 'Brian Kelleher'] 0.0\n",
      "nan nan\n",
      "['Alonzo Menifield', 'Dustin Jacoby'] 0.0\n",
      "['Tagir Ulanbekov', 'Cody Durden'] 1.0\n",
      "['Andre Fili', 'Lucas Almeida'] 1.0\n",
      "nan nan\n",
      "['Randy Brown', 'Muslim Salikhov'] 0.0\n",
      "['Magomed Ankalaev', 'Johnny Walker'] 0.0\n",
      "['Matheus Nicolau', 'Manel Kape'] 1.0\n",
      "['Jim Miller', 'Gabriel Benitez'] 0.0\n",
      "['Ketlen Vieira', 'Macy Chiasson'] 0.0\n",
      "['Ricky Simon', 'Mario Bautista'] 0.0\n",
      "['Phil Hawes', 'Brunno Ferreira'] 0.0\n",
      "['Andrei Arlovski', 'Waldo Cortes-Acosta'] 0.0\n",
      "['Bassil Hafez', 'Preston Parsons'] 1.0\n",
      "['Marcus McGhee', 'Gaston Bolanos'] 0.0\n",
      "['Yana Santos', 'Norma Dumont'] 0.0\n",
      "['Farid Basharat', 'Taylor Lapilus'] 0.0\n",
      "['Gabriel Santos', 'Westin Wilson'] 0.0\n",
      "nan nan\n",
      "['Sean Strickland', 'Dricus Du Plessis'] 1.0\n",
      "['Raquel Pennington', 'Mayra Bueno Silva'] 0.0\n",
      "['Neil Magny', 'Mike Malott'] 1.0\n",
      "['Jan Blachowicz', 'Aleksandar Rakic'] 1.0\n",
      "['Arnold Allen', 'Movsar Evloev'] 1.0\n",
      "['Dominick Reyes', 'Carlos Ulberg'] 1.0\n",
      "['Brad Katona', 'Garrett Armfield'] 1.0\n",
      "['Chris Curtis', 'Marc-Andre Barriault'] 0.0\n",
      "['Charles Jourdain', 'Sean Woodson'] 1.0\n",
      "nan nan\n",
      "['Gillian Robertson', 'Polyana Viana'] 0.0\n",
      "['Yohan Lainesse', 'Sam Patterson'] 0.0\n",
      "['Malcolm Gordon', 'Jimmy Flick'] 1.0\n",
      "['Jasmine Jasudavicius', 'Priscila Cachoeira'] 0.0\n",
      "['Roman Dolidze', 'Nassourdine Imavov'] 0.0\n",
      "['Jack Hermansson', 'Joe Pyfer'] 1.0\n",
      "['Alexander Volkanovski', 'Ilia Topuria'] 1.0\n",
      "nan nan\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lutas)):\n",
    "    print(fighters[i],\n",
    "          most_common_voting_clf_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
